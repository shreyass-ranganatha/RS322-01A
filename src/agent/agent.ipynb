{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aed475b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel\n",
    "from ollama import generate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2dd158a",
   "metadata": {},
   "source": [
    "## Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec09810c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_objects(image: str, prompt: str) -> dict:\n",
    "    pass\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a03053df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GenerateResponse(model='llama3.2:latest', created_at='2025-05-12T09:05:40.385159Z', done=True, done_reason='stop', total_duration=736675709, load_duration=35330417, prompt_eval_count=404, prompt_eval_duration=153398333, eval_count=27, eval_duration=547391833, response='{\\n  \"tool_name\": \"detect_objects\",\\n  \"tool_kwargs\": {\\n    \"object_class\": \".\"\\n  }\\n}', context=[128006, 9125, 128007, 271, 38766, 1303, 33025, 2696, 25, 6790, 220, 2366, 18, 271, 2675, 527, 264, 11376, 44658, 8479, 430, 8779, 3932, 24564, 5448, 1701, 264, 18468, 5507, 382, 1820, 1646, 374, 27785, 16572, 449, 330, 1030, 27357, 1, 323, 330, 76, 5281, 1, 6989, 382, 2675, 617, 2680, 311, 279, 2768, 734, 512, 11192, 62343, 25915, 10281, 2703, 25, 925, 11, 1665, 4895, 25, 925, 8, 11651, 34387, 82, 682, 6302, 12864, 279, 2728, 538, 304, 279, 2217, 323, 4780, 11408, 320, 62679, 15039, 11, 14921, 11, 12410, 12483, 4390, 45464, 66454, 4184, 311, 279, 2768, 5718, 1473, 16, 13, 1442, 279, 1217, 374, 10371, 499, 311, 3146, 62343, 334, 477, 3146, 3990, 334, 6302, 304, 459, 2217, 11, 471, 1193, 264, 4823, 1665, 304, 420, 3645, 512, 517, 220, 330, 14506, 13735, 794, 330, 62343, 25915, 761, 220, 330, 2164, 794, 341, 262, 330, 1843, 2703, 794, 330, 928, 498, 692, 443, 2539, 1853, 311, 279, 2217, 198, 262, 330, 1735, 4895, 794, 330, 928, 1, 260, 443, 384, 1326, 2637, 330, 1030, 27357, 5021, 498, 330, 7063, 498, 5099, 627, 220, 457, 633, 41481, 1473, 16, 13, 10765, 34557, 12690, 304, 279, 2217, 198, 517, 220, 330, 14506, 13735, 794, 330, 62343, 25915, 761, 220, 330, 2164, 794, 341, 262, 330, 1843, 2703, 794, 3605, 2398, 33529, 24234, 4924, 761, 262, 330, 1735, 4895, 794, 330, 1030, 27357, 662, 702, 220, 457, 633, 17, 13, 1505, 682, 12690, 304, 279, 2217, 198, 517, 220, 330, 14506, 13735, 794, 330, 62343, 25915, 761, 220, 330, 2164, 794, 341, 262, 330, 1843, 2703, 794, 3605, 2398, 33529, 24234, 4924, 761, 262, 330, 1735, 4895, 794, 330, 1030, 27357, 662, 70368, 662, 702, 220, 457, 633, 18, 13, 1505, 1396, 315, 34557, 12690, 304, 279, 2217, 198, 517, 220, 330, 14506, 13735, 794, 330, 62343, 25915, 761, 220, 330, 2164, 794, 341, 262, 330, 1843, 2703, 794, 3605, 2398, 33529, 24234, 4924, 761, 262, 330, 1735, 4895, 794, 330, 1030, 27357, 662, 702, 220, 457, 633, 38195, 1833, 4823, 37666, 24559, 994, 47128, 264, 5507, 13, 3234, 539, 2997, 904, 16540, 477, 5217, 31710, 7389, 279, 1217, 374, 10371, 264, 1833, 5352, 3488, 627, 128009, 128006, 882, 128007, 271, 6854, 499, 10765, 682, 6302, 304, 420, 2217, 30, 611, 7283, 15030, 8233, 300, 14, 50878, 14, 1993, 287, 67, 3394, 12986, 13586, 24234, 62, 931, 16, 4924, 128009, 128006, 78191, 128007, 271, 517, 220, 330, 14506, 1292, 794, 330, 62343, 25915, 761, 220, 330, 14506, 37335, 794, 341, 262, 330, 1735, 4895, 794, 6058, 702, 220, 457, 92])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SYSTEM_PROMPT = \"\"\"\n",
    "You are a helpful assistant tasked with answering my queries with respect to geospatial data.\n",
    "You are connecting to a GroundingDINO+SAM based tool that can help you with this task.\n",
    "\n",
    "Your capabilities include:\n",
    "1. object detection (for trees)\n",
    "2. image segmentation (for trees)\n",
    "3. image classification (for trees)\n",
    "4. image density map generation (for trees)\n",
    "\n",
    "the model is only trained with \"coconut\" and \"mango\" classes.\n",
    "\n",
    "when you want to generate a certain response, call the tool with the relevant prompt.\n",
    "\n",
    "for example,\n",
    "1.\n",
    "user: identify the trees in the image\n",
    "assistant: find_objects(\"coconut . mango .\")\n",
    "\n",
    "2.\n",
    "user: identify coconut trees in the image\n",
    "assistant: find_objects(\"coconut .\")\n",
    "\n",
    "3.\n",
    "user: find number of coconut trees in the image\n",
    "assistant: find_objects(\"coconut .\")\n",
    "\n",
    "All tools will return answers in the following format:\n",
    "{\n",
    "    \"response_image\": \"<file urlpath>\",\n",
    "    \"total_count\": <int>,\n",
    "    \"label_counts\": {\n",
    "        \"coconut tree\": <int>,\n",
    "        \"banyan tree\": <int>\n",
    "    },\n",
    "    \"mean_confidence\": <float>\n",
    "}\n",
    "\n",
    "You have in your possession a few tools that can help you with this task.\n",
    "\n",
    "\n",
    "The tools are:\n",
    "\n",
    "1. `find_objects(image_path, prompts)`:\n",
    "    Object detection tool that can identify boxes around objects in an image.\n",
    "    It takes in two parameters:\n",
    "    - image_path: The path to the image file.\n",
    "    - prompts: The classes of objects you want to detect in the image\n",
    "\n",
    "2. `segment_objects(image_path, prompts)`:\n",
    "    Image segmentation tool that can identify pixels of objects in an image.\n",
    "    It takes in two parameters:\n",
    "    - image_path: The path to the image file.\n",
    "    - prompts: The classes of objects you want to segment in the image\n",
    "\n",
    "3. `density_map(image_path, prompts)`:\n",
    "    Image density map generation tool that can identify the density of objects in an image.\n",
    "    It takes in two parameters:\n",
    "    - image_path: The path to the image file.\n",
    "    - prompts: The classes of objects you want to generate a density map for\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "SYSTEM_PROMPT = \"\"\"You are a vision-language agent that helps users analyze images using a detection tool.\n",
    "\n",
    "the model is ONLY trained with \"coconut\" and \"mango\" classes.\n",
    "\n",
    "You have access to the following function:\n",
    "---\n",
    "detect_objects(image_path: string, object_class: string) â†’ Detects all objects matching the given class in the image and returns metadata (bounding boxes, counts, confidence scores).\n",
    "---\n",
    "\n",
    "Respond according to the following rules:\n",
    "\n",
    "1. If the user is asking you to **detect** or **find** objects in an image, return only a JSON object in this format:\n",
    "{\n",
    "  \"tool_call\": \"detect_objects\",\n",
    "  \"args\": {\n",
    "    \"image_path\": \"string\",          // full path to the image\n",
    "    \"object_class\": \"string\"         // e.g., \"coconut tree\", \"car\", etc.\n",
    "  }\n",
    "}\n",
    "\n",
    "Examples:\n",
    "\n",
    "1. identify coconut trees in the image\n",
    "{\n",
    "  \"tool_call\": \"detect_objects\",\n",
    "  \"args\": {\n",
    "    \"image_path\": \"/path/to/image.jpg\",\n",
    "    \"object_class\": \"coconut .\"\n",
    "  }\n",
    "}\n",
    "\n",
    "2. find all trees in the image\n",
    "{\n",
    "  \"tool_call\": \"detect_objects\",\n",
    "  \"args\": {\n",
    "    \"image_path\": \"/path/to/image.jpg\",\n",
    "    \"object_class\": \"coconut . mango .\"\n",
    "  }\n",
    "}\n",
    "\n",
    "3. find number of coconut trees in the image\n",
    "{\n",
    "  \"tool_call\": \"detect_objects\",\n",
    "  \"args\": {\n",
    "    \"image_path\": \"/path/to/image.jpg\",\n",
    "    \"object_class\": \"coconut .\"\n",
    "  }\n",
    "}\n",
    "\n",
    "Always follow JSON formatting precisely when invoking a tool. Do not include any explanation or additional commentary unless the user is asking a follow-up question.\n",
    "\"\"\"\n",
    "\n",
    "class ResponseModel(BaseModel):\n",
    "    tool_name: str\n",
    "    tool_kwargs: dict[str, str]\n",
    "\n",
    "rsp = generate(\n",
    "    model=\"llama3.2:latest\",\n",
    "    prompt=\"Can you identify all objects in this image? /Users/shreyas/Downloads/groundingdino/test_images/image_0001.jpg\",\n",
    "    system=SYSTEM_PROMPT,\n",
    "    format=ResponseModel.model_json_schema(),)\n",
    "\n",
    "rsp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "15f1ca25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"tool_name\": \"detect_objects\",\n",
      "  \"tool_kwargs\": {\n",
      "    \"object_class\": \".\"\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(rsp.response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "groundingdino",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
